#!/usr/bin/env python3
"""
AI Prompt Quality Evaluator

í”„ë¡¬í”„íŠ¸ í’ˆì§ˆì„ ì •ëŸ‰ì ìœ¼ë¡œ í‰ê°€í•˜ê³  ê°œì„  ë°©í–¥ì„ ì œì‹œí•˜ëŠ” ë„êµ¬.
ì‹¤í–‰ ë¡œê·¸ ê¸°ë°˜, dry-run ì „ìš©.
"""

import sqlite3
from pathlib import Path
from collections import defaultdict
import statistics
import json

DB_PATH = Path(__file__).resolve().parents[1] / "shared" / "data" / "trading.db"

def connect_db():
    if not DB_PATH.exists():
        return None
    try:
        conn = sqlite3.connect(f"file:{DB_PATH}?mode=ro", uri=True, timeout=10)
        return conn
    except:
        return None

class PromptEvaluator:
    """AI í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ í‰ê°€ê¸°"""
    
    def __init__(self, conn):
        self.conn = conn
    
    def get_signal_distribution(self):
        """
        ì‹ í˜¸ ì ìˆ˜ ë¶„í¬ ë¶„ì„
        
        ë°˜í™˜:
            dict: mean, std, min, max, count
        """
        try:
            cursor = self.conn.execute(
                "SELECT ai_score FROM execution_log WHERE module='APP64'"
            )
            scores = [row[0] for row in cursor.fetchall()]
            
            if not scores:
                return None
            
            return {
                'count': len(scores),
                'mean': round(statistics.mean(scores), 4),
                'stdev': round(statistics.stdev(scores), 4) if len(scores) > 1 else 0.0,
                'min': round(min(scores), 4),
                'max': round(max(scores), 4),
                'median': round(statistics.median(scores), 4),
            }
        except:
            return None
    
    def get_discrimination_index(self):
        """
        íŒë³„ë ¥ ì§€ìˆ˜ ê³„ì‚° (DI)
        
        DI > 1.0: ì¢‹ì€ íŒë³„ë ¥
        DI 0.5-1.0: ì¤‘ê°„ íŒë³„ë ¥
        DI < 0.5: ë‚˜ìœ íŒë³„ë ¥
        """
        try:
            # SENT ì‹ í˜¸
            cursor = self.conn.execute(
                "SELECT ai_score FROM execution_log WHERE module='APP32' AND decision='SENT'"
            )
            sent_scores = [row[0] for row in cursor.fetchall()]
            
            # REJECTED ì‹ í˜¸
            cursor = self.conn.execute(
                "SELECT ai_score FROM execution_log WHERE module='APP32' AND decision='REJECTED'"
            )
            rejected_scores = [row[0] for row in cursor.fetchall()]
            
            if not sent_scores or not rejected_scores:
                return None
            
            sent_mean = statistics.mean(sent_scores)
            rejected_mean = statistics.mean(rejected_scores)
            sent_std = statistics.stdev(sent_scores) if len(sent_scores) > 1 else 0.001
            rejected_std = statistics.stdev(rejected_scores) if len(rejected_scores) > 1 else 0.001
            
            di = (sent_mean - rejected_mean) / (sent_std + rejected_std)
            
            return {
                'DI': round(di, 4),
                'SENT_mean': round(sent_mean, 4),
                'SENT_std': round(sent_std, 4),
                'SENT_count': len(sent_scores),
                'REJECTED_mean': round(rejected_mean, 4),
                'REJECTED_std': round(rejected_std, 4),
                'REJECTED_count': len(rejected_scores),
                'score_gap': round(sent_mean - rejected_mean, 4),
            }
        except:
            return None
    
    def get_rejection_analysis(self):
        """
        ê±°ì ˆ ì´ìœ ë³„ ì ìˆ˜ ë¶„ì„
        """
        try:
            cursor = self.conn.execute(
                "SELECT rejection_reason, ai_score FROM execution_log WHERE decision='REJECTED'"
            )
            
            reason_scores = defaultdict(list)
            total = 0
            
            for reason, score in cursor.fetchall():
                reason_scores[reason].append(score)
                total += 1
            
            result = {}
            for reason in reason_scores:
                scores = reason_scores[reason]
                result[reason] = {
                    'count': len(scores),
                    'pct': round(100.0 * len(scores) / total, 2),
                    'mean_score': round(statistics.mean(scores), 4),
                    'min_score': round(min(scores), 4),
                    'max_score': round(max(scores), 4),
                }
            
            return dict(sorted(result.items(), key=lambda x: x[1]['count'], reverse=True))
        except:
            return None
    
    def get_symbol_bias(self):
        """
        ì¢…ëª©ë³„ í¸í–¥ ë¶„ì„
        """
        try:
            cursor = self.conn.execute(
                "SELECT symbol, ai_score FROM execution_log WHERE module='APP32'"
            )
            
            symbol_scores = defaultdict(list)
            
            for symbol, score in cursor.fetchall():
                symbol_scores[symbol].append(score)
            
            result = {}
            for symbol in symbol_scores:
                scores = symbol_scores[symbol]
                result[symbol] = {
                    'count': len(scores),
                    'mean_score': round(statistics.mean(scores), 4),
                    'std_score': round(statistics.stdev(scores), 4) if len(scores) > 1 else 0.0,
                }
            
            # í¸í–¥ ì§€ìˆ˜
            if result:
                means = [v['mean_score'] for v in result.values()]
                bias_index = max(means) - min(means)
                result['_bias_index'] = round(bias_index, 4)
            
            return dict(sorted(result.items(), key=lambda x: x[1]['mean_score'] if isinstance(x[1], dict) else 0, reverse=True))
        except:
            return None
    
    def get_time_bias(self):
        """
        ì‹œê°„ëŒ€ë³„ í¸í–¥ ë¶„ì„
        """
        try:
            cursor = self.conn.execute(
                "SELECT strftime('%H', ts) as hour, ai_score FROM execution_log WHERE module='APP32'"
            )
            
            hour_scores = defaultdict(list)
            
            for hour, score in cursor.fetchall():
                hour_scores[hour].append(score)
            
            result = {}
            all_means = []
            
            for hour in sorted(hour_scores.keys()):
                scores = hour_scores[hour]
                mean = statistics.mean(scores)
                all_means.append(mean)
                result[hour] = {
                    'count': len(scores),
                    'mean_score': round(mean, 4),
                    'std_score': round(statistics.stdev(scores), 4) if len(scores) > 1 else 0.0,
                }
            
            # ì‹œê°„ í¸í–¥ ì§€ìˆ˜
            if all_means:
                time_bias = max(all_means) - min(all_means)
                result['_time_bias'] = round(time_bias, 4)
            
            return result
        except:
            return None
    
    def diagnose_problems(self):
        """
        í”„ë¡¬í”„íŠ¸ ë¬¸ì œ ìë™ ì§„ë‹¨
        """
        diagnostics = []
        
        # ì‹ í˜¸ ë¶„í¬ ê²€ì‚¬
        sig_dist = self.get_signal_distribution()
        if sig_dist:
            if sig_dist['mean'] > 0.80:
                diagnostics.append({
                    'type': 'OVER_AGGRESSIVE',
                    'severity': 'HIGH',
                    'description': f"í‰ê·  ì ìˆ˜ê°€ {sig_dist['mean']}ë¡œ ê³¼ë„í•˜ê²Œ ë†’ìŒ",
                    'action': 'í”„ë¡¬í”„íŠ¸: ë‚®ì€ ì ìˆ˜ ì‹ í˜¸ ìƒì„± ì¥ë ¤'
                })
            elif sig_dist['mean'] < 0.60:
                diagnostics.append({
                    'type': 'OVER_CONSERVATIVE',
                    'severity': 'HIGH',
                    'description': f"í‰ê·  ì ìˆ˜ê°€ {sig_dist['mean']}ë¡œ ê³¼ë„í•˜ê²Œ ë‚®ìŒ",
                    'action': 'í”„ë¡¬í”„íŠ¸: ë†’ì€ ì ìˆ˜ ì‹ í˜¸ ìƒì„± ì¥ë ¤'
                })
            
            if sig_dist['stdev'] < 0.05:
                diagnostics.append({
                    'type': 'LOW_VARIANCE',
                    'severity': 'MEDIUM',
                    'description': f"í‘œì¤€í¸ì°¨ {sig_dist['stdev']}ë¡œ ì‹ í˜¸ ë‹¨ì¡°ë¡œì›€",
                    'action': 'í”„ë¡¬í”„íŠ¸: ëª…í™•í•œ í‰ê°€ ê¸°ì¤€ë³„ êµ¬ë¶„ ì¶”ê°€'
                })
            elif sig_dist['stdev'] > 0.15:
                diagnostics.append({
                    'type': 'HIGH_VARIANCE',
                    'severity': 'MEDIUM',
                    'description': f"í‘œì¤€í¸ì°¨ {sig_dist['stdev']}ë¡œ ì‹ í˜¸ ë¶ˆì¼ê´€",
                    'action': 'í”„ë¡¬í”„íŠ¸: í‰ê°€ ê¸°ì¤€ ëª…í™•í™”'
                })
        
        # íŒë³„ë ¥ ê²€ì‚¬
        di_data = self.get_discrimination_index()
        if di_data:
            if di_data['DI'] < 0.5:
                diagnostics.append({
                    'type': 'POOR_DISCRIMINATION',
                    'severity': 'HIGH',
                    'description': f"íŒë³„ë ¥ ì§€ìˆ˜ {di_data['DI']} (SENTì™€ REJECTED ì ìˆ˜ ìœ ì‚¬)",
                    'action': 'í•„í„°ê°€ ì •ìƒì´ë©´ í”„ë¡¬í”„íŠ¸ ì‹ í˜¸ í’ˆì§ˆ ê°œì„  í•„ìš”'
                })
        
        # ê±°ì ˆ ì´ìœ  ê²€ì‚¬
        rejection = self.get_rejection_analysis()
        if rejection:
            for reason, data in rejection.items():
                if data['mean_score'] > 0.76:
                    diagnostics.append({
                        'type': 'GOOD_SIGNALS_REJECTED',
                        'severity': 'MEDIUM',
                        'description': f"{reason}ë¡œ ê±°ì ˆëœ ì‹ í˜¸ì˜ í‰ê·  ì ìˆ˜ {data['mean_score']}",
                        'action': f'í•„í„° ì„¤ì • ê²€í†  í•„ìš” ({reason} ì„ê³„ê°’ ì™„í™”?)'
                    })
        
        # í¸í–¥ ê²€ì‚¬
        symbol_bias = self.get_symbol_bias()
        if symbol_bias and '_bias_index' in symbol_bias:
            if symbol_bias['_bias_index'] > 0.05:
                diagnostics.append({
                    'type': 'SYMBOL_BIAS',
                    'severity': 'MEDIUM',
                    'description': f"ì¢…ëª© í¸í–¥ ì§€ìˆ˜ {symbol_bias['_bias_index']}",
                    'action': 'í”„ë¡¬í”„íŠ¸: ì¢…ëª©ë³„ ë™ë“± í‰ê°€ ê¸°ì¤€ ì¶”ê°€'
                })
        
        time_bias = self.get_time_bias()
        if time_bias and '_time_bias' in time_bias:
            if time_bias['_time_bias'] > 0.03:
                diagnostics.append({
                    'type': 'TIME_BIAS',
                    'severity': 'LOW',
                    'description': f"ì‹œê°„ëŒ€ í¸í–¥ ì§€ìˆ˜ {time_bias['_time_bias']}",
                    'action': 'í”„ë¡¬í”„íŠ¸: ì‹œê°„ ë…ë¦½ì„± ê°•í™”'
                })
        
        return diagnostics

def print_header(text):
    print(f"\n{'='*70}")
    print(f"  {text}")
    print(f"{'='*70}\n")

def print_section(text):
    print(f"\n{text}")
    print(f"{'-'*70}")

def main():
    print("\n" + "="*70)
    print("  AI TRADING PROMPT QUALITY EVALUATOR")
    print("  Data-driven evaluation of signal generation quality")
    print("="*70)
    
    conn = connect_db()
    if not conn:
        print("\nâŒ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   APP64ì™€ APP32ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
        return
    
    evaluator = PromptEvaluator(conn)
    
    try:
        # 1. ì‹ í˜¸ ë¶„í¬
        print_section("ğŸ“Š 1. Signal Distribution Analysis")
        sig_dist = evaluator.get_signal_distribution()
        
        if sig_dist:
            print(f"Total signals generated:  {sig_dist['count']:>6}")
            print(f"Mean score:               {sig_dist['mean']:>6.4f}")
            print(f"Std deviation:            {sig_dist['stdev']:>6.4f}")
            print(f"Score range:              {sig_dist['min']:.4f} ~ {sig_dist['max']:.4f}")
            print(f"Median score:             {sig_dist['median']:>6.4f}")
            
            print("\nğŸ’¡ Interpretation:")
            if 0.65 < sig_dist['mean'] < 0.75 and 0.08 < sig_dist['stdev'] < 0.13:
                print("   âœ… ì–‘í˜¸: ì ì ˆí•œ ì‹ í˜¸ ë¶„í¬")
            elif sig_dist['mean'] > 0.80:
                print("   âš ï¸  ê³¼ë„í•˜ê²Œ ê³µê²©ì : ëŒ€ë¶€ë¶„ì˜ ì‹ í˜¸ ì ìˆ˜ê°€ ë†’ìŒ")
                print("       â†’ í”„ë¡¬í”„íŠ¸ì—ì„œ ë‚®ì€ ì ìˆ˜ ì‹ í˜¸ ìƒì„± ì¥ë ¤")
            elif sig_dist['mean'] < 0.60:
                print("   âš ï¸  ê³¼ë„í•˜ê²Œ ë³´ìˆ˜ì : ì‹ í˜¸ ê°œìˆ˜ê°€ ì ì„ ê°€ëŠ¥ì„±")
                print("       â†’ í”„ë¡¬í”„íŠ¸ì—ì„œ ì‹ í˜¸ ìƒì„± ì„ê³„ê°’ ë‚®ì¶¤")
            
            if sig_dist['stdev'] < 0.05:
                print("   âš ï¸  ì‹ í˜¸ ë‹¨ì¡°ë¡œì›€: í‰ê°€ ê¸°ì¤€ì´ ë¶ˆëª…í™•í•œ ê²ƒìœ¼ë¡œ ë³´ì„")
            elif sig_dist['stdev'] > 0.15:
                print("   âš ï¸  ì‹ í˜¸ ë¶ˆì¼ê´€: í‰ê°€ ê¸°ì¤€ì´ ì¼ì •í•˜ì§€ ì•ŠìŒ")
        else:
            print("No signal data available yet.")
        
        # 2. íŒë³„ë ¥ ì§€ìˆ˜
        print_section("ğŸ¯ 2. Discrimination Index (SENT vs REJECTED)")
        di_data = evaluator.get_discrimination_index()
        
        if di_data:
            print(f"Discrimination Index:     {di_data['DI']:>6.4f}")
            print(f"\nSENT signals:")
            print(f"  Count:                  {di_data['SENT_count']:>6}")
            print(f"  Mean score:             {di_data['SENT_mean']:>6.4f}")
            print(f"  Std deviation:          {di_data['SENT_std']:>6.4f}")
            print(f"\nREJECTED signals:")
            print(f"  Count:                  {di_data['REJECTED_count']:>6}")
            print(f"  Mean score:             {di_data['REJECTED_mean']:>6.4f}")
            print(f"  Std deviation:          {di_data['REJECTED_std']:>6.4f}")
            print(f"\nScore gap (SENT - REJECTED): {di_data['score_gap']:>6.4f}")
            
            print("\nğŸ’¡ Interpretation:")
            if di_data['DI'] > 1.0:
                print("   âœ… ìš°ìˆ˜: AI ì‹ í˜¸ê°€ ìœ íš¨í•œ íŒë³„ë ¥ ìˆìŒ")
            elif di_data['DI'] > 0.5:
                print("   âš ï¸  ì¤‘ê°„: íŒë³„ë ¥ì€ ìˆì§€ë§Œ ê°œì„  ì—¬ì§€ ìˆìŒ")
            else:
                print("   âŒ ë¶€ì¡±: SENTì™€ REJECTED ì ìˆ˜ êµ¬ë¶„ ì•ˆ ë¨")
                print("       â†’ í”„ë¡¬í”„íŠ¸ì˜ í‰ê°€ ê¸°ì¤€ ëª…í™•í™” í•„ìš”")
        else:
            print("No execution data available yet.")
        
        # 3. ê±°ì ˆ ì´ìœ  ë¶„ì„
        print_section("ğŸš« 3. Rejection Reason Analysis")
        rejection = evaluator.get_rejection_analysis()
        
        if rejection:
            print(f"{'Reason':<20} {'Count':>6} {'%':>6} {'Avg Score':>10}")
            print("-" * 50)
            for reason, data in rejection.items():
                score_quality = "HIGH" if data['mean_score'] > 0.76 else "OK" if data['mean_score'] > 0.70 else "LOW"
                print(f"{reason:<20} {data['count']:>6} {data['pct']:>5.1f}% {data['mean_score']:>10.4f} ({score_quality})")
            
            print("\nğŸ’¡ Interpretation:")
            high_score_rejections = [r for r, d in rejection.items() if d['mean_score'] > 0.76]
            if high_score_rejections:
                print(f"   âš ï¸  High-score signals rejected by: {', '.join(high_score_rejections)}")
                print("       â†’ ì´ í•„í„°ë“¤ì´ ì¢‹ì€ ì‹ í˜¸ë¥¼ ì°¨ë‹¨í•˜ê³  ìˆìŒ")
                print("       â†’ í•„í„° ì„¤ì • ê²€í†  í•„ìš” (TTL ì¦ê°€? ì¿¨ë‹¤ìš´ ê°ì†Œ?)")
        else:
            print("No rejection data available yet.")
        
        # 4. ì¢…ëª© í¸í–¥
        print_section("ğŸ“ˆ 4. Symbol Bias Analysis")
        symbol_bias = evaluator.get_symbol_bias()
        
        if symbol_bias and len(symbol_bias) > 1:
            bias_index = symbol_bias.pop('_bias_index', 0)
            
            print(f"{'Symbol':<10} {'Count':>6} {'Avg Score':>10}")
            print("-" * 30)
            for symbol, data in symbol_bias.items():
                print(f"{symbol:<10} {data['count']:>6} {data['mean_score']:>10.4f}")
            
            print(f"\nBias Index: {bias_index:.4f}")
            
            print("\nğŸ’¡ Interpretation:")
            if bias_index < 0.03:
                print("   âœ… ì–‘í˜¸: ì¢…ëª© ê°„ ê· í˜• ì¡í˜")
            elif bias_index < 0.05:
                print("   âš ï¸  ì•½í•œ í¸í–¥: ì•½ê°„ì˜ ì¢…ëª© ì„ í˜¸ ìˆìŒ")
            else:
                print("   âŒ ì‹¬í•œ í¸í–¥: íŠ¹ì • ì¢…ëª©ì„ ì„ í˜¸í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì„")
                print("       â†’ í”„ë¡¬í”„íŠ¸: ì¢…ëª©ë³„ ë™ë“± í‰ê°€ ê¸°ì¤€ ì¶”ê°€")
        else:
            print("Insufficient symbol data.")
        
        # 5. ì‹œê°„ í¸í–¥
        print_section("â° 5. Time-of-Day Bias Analysis")
        time_bias = time_bias = evaluator.get_time_bias()
        
        if time_bias and len(time_bias) > 1:
            time_bias_index = time_bias.pop('_time_bias', 0)
            
            print(f"{'Hour':<6} {'Count':>6} {'Avg Score':>10}")
            print("-" * 30)
            for hour in sorted(time_bias.keys()):
                data = time_bias[hour]
                print(f"{hour:<6} {data['count']:>6} {data['mean_score']:>10.4f}")
            
            print(f"\nTime Bias Index: {time_bias_index:.4f}")
            
            print("\nğŸ’¡ Interpretation:")
            if time_bias_index < 0.03:
                print("   âœ… ì–‘í˜¸: ì‹œê°„ë³„ ì‹ í˜¸ ê· í˜•")
            else:
                print("   âš ï¸  ì‹œê°„ í¸í–¥: íŠ¹ì • ì‹œê°„ëŒ€ ì‹ í˜¸ í’ˆì§ˆ í¸ì°¨")
                print("       â†’ í”„ë¡¬í”„íŠ¸: ì‹œê°„ ë…ë¦½ì„± ê°•í™”")
        else:
            print("Insufficient time-series data.")
        
        # 6. ìë™ ì§„ë‹¨
        print_section("ğŸ” 6. Automatic Diagnosis")
        diagnostics = evaluator.diagnose_problems()
        
        if diagnostics:
            print(f"ë°œê²¬ëœ ë¬¸ì œ: {len(diagnostics)}ê°œ\n")
            
            for i, diag in enumerate(diagnostics, 1):
                severity_emoji = "âŒ" if diag['severity'] == 'HIGH' else "âš ï¸ " if diag['severity'] == 'MEDIUM' else "â„¹ï¸ "
                print(f"{severity_emoji} [{diag['type']}] {diag['description']}")
                print(f"   â†’ {diag['action']}\n")
        else:
            print("âœ… í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ ì–‘í˜¸: ì£¼ìš” ë¬¸ì œ ì—†ìŒ")
        
        # ìµœì¢… ê¶Œì¥ì‚¬í•­
        print_section("ğŸ“‹ Final Recommendations")
        print("""
1. ìœ„ì˜ ì§„ë‹¨ ê²°ê³¼ë¥¼ ê²€í† í•˜ì„¸ìš”.
2. ê°€ì¥ ì‹¬ê°í•œ ë¬¸ì œë¶€í„° í•´ê²°í•˜ì„¸ìš”.
3. ê° ë³€ê²½ í›„ ìƒˆë¡œìš´ ë²„ì „ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì„¸ìš”:
   - strategy_params.jsonì˜ "version" ì¦ê°€
   - ìµœì†Œ ì¶©ë¶„í•œ ë°ì´í„° ìˆ˜ì§‘ (500+ ì‹ í˜¸)
4. ì´ì „ ë²„ì „ê³¼ ë¹„êµí•˜ì—¬ ê°œì„  ì—¬ë¶€ í™•ì¸í•˜ì„¸ìš”.
5. ëª¨ë“  ë°ì´í„°ëŠ” ì˜êµ¬ ë³´ê´€ë˜ë¯€ë¡œ ì–¸ì œë“  ë¹„êµ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        """)
        
    except Exception as e:
        print(f"\nâŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
    
    finally:
        conn.close()

if __name__ == "__main__":
    main()
